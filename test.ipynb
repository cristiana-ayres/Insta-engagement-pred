{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, time, urllib.request, openpyxl, operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from openpyxl import Workbook\n",
    "import sys, requests, re, json\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Create Empty List\n",
    "ranking = []\n",
    "username = []\n",
    "category = []\n",
    "category_2 = []\n",
    "\n",
    "def scrape_username(url):\n",
    "    \n",
    "    #accesing and parsing the input url\n",
    "    response = requests.get(url)\n",
    "    print(f'response {response}')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    list_username = soup.find_all('tr')\n",
    "    \n",
    "    #looping to the element that we want to scrape\n",
    "    for p in list(list_username):\n",
    "        try:\n",
    "            #getting the information (rank, names, and category)\n",
    "            rank = p.find('td', 'align-middle').get_text().strip()\n",
    "            ranking.append(rank)\n",
    "            name = p.find('a').get_text().strip()\n",
    "            username.append(name)\n",
    "            cat = p.find_all('span', 'badge badge-pill badge-light samll text-muted')\n",
    "            category_2 = []\n",
    "            for c in cat:\n",
    "                d = c.find('a', 'link').get_text()\n",
    "                category_2.append(d)\n",
    "            category.append(category_2)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return ranking, username, category\n",
    "\n",
    "#function to scrape general information\n",
    "def scrape_general_info(url):\n",
    "    # instagram URL \n",
    "    URL = url\n",
    "\n",
    "    # creating a dictionary \n",
    "    data = {} \n",
    "\n",
    "    # getting the request from url \n",
    "    r = requests.get(URL)\n",
    "\n",
    "    # converting the text \n",
    "    s = BeautifulSoup(r.text, \"html.parser\") \n",
    "\n",
    "    # finding meta info \n",
    "    meta = s.find(\"meta\", property =\"og:description\")\n",
    "\n",
    "    #searching followers, followeing and number of posts info\n",
    "    meta_2 = meta.attrs['content']\n",
    "    meta_3 = meta_2.split(\"-\")[0].split(\" \")\n",
    "\n",
    "    # assigning the values \n",
    "    data['Followers'] = meta_3[0] \n",
    "    data['Following'] = meta_3[2] \n",
    "    data['Posts'] = meta_3[4]\n",
    "    \n",
    "    return data\n",
    "\n",
    "#Create Empty List\n",
    "link = []\n",
    "names = []\n",
    "\n",
    "def get_influencer_link(username):\n",
    "    #to influencer url\n",
    "    url = f'https://www.instagram.com/{username}/'\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    i = 0\n",
    "    while i < 8:   \n",
    "        try:\n",
    "            #get the links\n",
    "            pages = driver.find_elements_by_tag_name('a')\n",
    "            for data in pages:\n",
    "                data_2 = data.get_attribute(\"href\")\n",
    "                if '/p/' in data_2:\n",
    "                    link.append(data.get_attribute(\"href\"))\n",
    "                    names.append(username)\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            time.sleep(1)\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "    driver.quit()\n",
    "\n",
    "    return link, names\n",
    "\n",
    "\n",
    "likes = []\n",
    "comment_counts = []\n",
    "dates = []\n",
    "captions = []\n",
    "type_posts = []\n",
    "links = []\n",
    "i = 0\n",
    "n = 0\n",
    "\n",
    "def get_information(link):    \n",
    "    try:\n",
    "        global i, n\n",
    "        \n",
    "        #accessing and parsing the website url\n",
    "        url = link\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "        \n",
    "        #find element that contain information\n",
    "        body = soup.find('body')\n",
    "        script = body.find('script')\n",
    "        raw = script.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "        json_data=json.loads(raw)\n",
    "        posts =json_data['entry_data']['PostPage'][0]['graphql']\n",
    "        posts= json.dumps(posts)\n",
    "        posts = json.loads(posts)\n",
    "        \n",
    "        #acquiring information\n",
    "        like = posts['shortcode_media']['edge_media_preview_like']['count']\n",
    "        comment_count = posts['shortcode_media']['edge_media_to_parent_comment']['count']\n",
    "        date = posts['shortcode_media']['taken_at_timestamp']\n",
    "        caption = posts['shortcode_media']['edge_media_to_caption']['edges'][0]['node']['text']\n",
    "        type_post = posts['shortcode_media']['__typename']\n",
    "        likes.append(like)\n",
    "        comment_counts.append(comment_count)\n",
    "        dates.append(date)\n",
    "        captions.append(caption)\n",
    "        type_posts.append(type_post)\n",
    "        links.append(link)\n",
    "        i += 1\n",
    "    except:\n",
    "        i += 1\n",
    "        n += 1\n",
    "        print(f'number of link error {n} at iteration {i}')\n",
    "        pass\n",
    "    return likes, comment_counts, dates, captions, type_posts, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, time, urllib.request, openpyxl, operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from openpyxl import Workbook\n",
    "import sys, requests, re, json\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# import utils\n",
    "# from utils import scrape_username, scrape_general_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#scrape username instagram that we want to analyze\n",
    "for i in range(10): #bcs the number of webpage is until 10\n",
    "    a = i+1\n",
    "    #if response 200 is that webpage can be scraped\n",
    "    url = f'https://starngage.com/app/id/influencer/ranking/brazil'\n",
    "    \n",
    "    #call function\n",
    "    ranking, username, category = scrape_username(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_dict = {\n",
    "    'username':username,\n",
    "    'ranking':ranking,\n",
    "    'category' : category\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign to dataframe\n",
    "df = pd.DataFrame(inf_dict)\n",
    "\n",
    "#do some preprocessing\n",
    "df['username_2'] = df['username'].apply(lambda x: x[1:])\n",
    "df['category'] = df['category'].astype('str')\n",
    "df_2 = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>ranking</th>\n",
       "      <th>category</th>\n",
       "      <th>username_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td></td>\n",
       "      <td>96</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td></td>\n",
       "      <td>97</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td></td>\n",
       "      <td>98</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td></td>\n",
       "      <td>99</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td></td>\n",
       "      <td>100</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   username ranking category username_2\n",
       "0                 1       []           \n",
       "1                 2       []           \n",
       "2                 3       []           \n",
       "3                 4       []           \n",
       "4                 5       []           \n",
       "..      ...     ...      ...        ...\n",
       "95               96       []           \n",
       "96               97       []           \n",
       "97               98       []           \n",
       "98               99       []           \n",
       "99              100       []           \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Ironhack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "854afc56d03903cb43ce0c2669a823476d92c4ce89f442894441f6714fb107d5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
