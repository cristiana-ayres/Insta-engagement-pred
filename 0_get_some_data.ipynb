{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, time, urllib.request, openpyxl, operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from openpyxl import Workbook\n",
    "import sys, requests, re, json\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Create Empty List\n",
    "ranking = []\n",
    "username = []\n",
    "category = []\n",
    "category_2 = []\n",
    "\n",
    "def scrape_username(url):\n",
    "    \n",
    "    #accesing and parsing the input url\n",
    "    response = requests.get(url)\n",
    "    print(f'response {response}')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    list_username = soup.find_all('tr')\n",
    "    \n",
    "    #looping to the element that we want to scrape\n",
    "    for p in list(list_username):\n",
    "        try:\n",
    "            #getting the information (rank, names, and category)\n",
    "            rank = p.find('td', 'align-middle').get_text().strip()\n",
    "            ranking.append(rank)\n",
    "\n",
    "            # name = p.find_all('a', \"_blank\").get_text().strip()\n",
    "            # name_2 = []\n",
    "            # for item in name:\n",
    "            #     new_var = item.find('a', 'link').get_text()\n",
    "            #     name_2.append(new_var)\n",
    "            # username.append(name_2)\n",
    "\n",
    "            name = p.find('a').get_text().strip()\n",
    "            username.append(name)\n",
    "\n",
    "\n",
    "            cat = p.find_all('span', 'badge badge-pill badge-light samll font-weight-normal text-muted') #i had to change this part here to get categories\n",
    "            category_2 = []\n",
    "            for c in cat:\n",
    "                d = c.find('a', 'link').get_text()\n",
    "                category_2.append(d)\n",
    "            category.append(category_2)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return ranking, username, category\n",
    "\n",
    "#function to scrape general information\n",
    "def scrape_general_info(url):\n",
    "    # instagram URL \n",
    "    URL = url\n",
    "\n",
    "    # creating a dictionary \n",
    "    data = {} \n",
    "\n",
    "    # getting the request from url \n",
    "    r = requests.get(URL)\n",
    "\n",
    "    # converting the text \n",
    "    s = BeautifulSoup(r.text, \"html.parser\") \n",
    "\n",
    "    # finding meta info \n",
    "    meta = s.find(\"meta\", property =\"og:description\")\n",
    "\n",
    "    #searching followers, followeing and number of posts info\n",
    "    meta_2 = meta.attrs['content']\n",
    "    meta_3 = meta_2.split(\"-\")[0].split(\" \")\n",
    "\n",
    "    # assigning the values \n",
    "    data['Followers'] = meta_3[0] \n",
    "    data['Following'] = meta_3[2] \n",
    "    data['Posts'] = meta_3[4]\n",
    "    \n",
    "    return data\n",
    "\n",
    "#Create Empty List\n",
    "link = []\n",
    "names = []\n",
    "\n",
    "def get_influencer_link(username):\n",
    "    #to influencer url\n",
    "    url = f'https://www.instagram.com/{username}/'\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    i = 0\n",
    "    while i < 8:   \n",
    "        try:\n",
    "            #get the links\n",
    "            pages = driver.find_elements_by_tag_name('a')\n",
    "            for data in pages:\n",
    "                data_2 = data.get_attribute(\"href\")\n",
    "                if '/p/' in data_2:\n",
    "                    link.append(data.get_attribute(\"href\"))\n",
    "                    names.append(username)\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            time.sleep(1)\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "    driver.quit()\n",
    "\n",
    "    return link, names\n",
    "\n",
    "\n",
    "likes = []\n",
    "comment_counts = []\n",
    "dates = []\n",
    "captions = []\n",
    "type_posts = []\n",
    "links = []\n",
    "i = 0\n",
    "n = 0\n",
    "\n",
    "def get_information(link):    \n",
    "    try:\n",
    "        global i, n\n",
    "        \n",
    "        #accessing and parsing the website url\n",
    "        url = link\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "        \n",
    "        #find element that contain information\n",
    "        body = soup.find('body')\n",
    "        script = body.find('script')\n",
    "        raw = script.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "        json_data=json.loads(raw)\n",
    "        posts =json_data['entry_data']['PostPage'][0]['graphql']\n",
    "        posts= json.dumps(posts)\n",
    "        posts = json.loads(posts)\n",
    "        \n",
    "        #acquiring information\n",
    "        like = posts['shortcode_media']['edge_media_preview_like']['count']\n",
    "        comment_count = posts['shortcode_media']['edge_media_to_parent_comment']['count']\n",
    "        date = posts['shortcode_media']['taken_at_timestamp']\n",
    "        caption = posts['shortcode_media']['edge_media_to_caption']['edges'][0]['node']['text']\n",
    "        type_post = posts['shortcode_media']['__typename']\n",
    "        likes.append(like)\n",
    "        comment_counts.append(comment_count)\n",
    "        dates.append(date)\n",
    "        captions.append(caption)\n",
    "        type_posts.append(type_post)\n",
    "        links.append(link)\n",
    "        i += 1\n",
    "    except:\n",
    "        i += 1\n",
    "        n += 1\n",
    "        print(f'number of link error {n} at iteration {i}')\n",
    "        pass\n",
    "    return likes, comment_counts, dates, captions, type_posts, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, time, urllib.request, openpyxl, operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from openpyxl import Workbook\n",
    "import sys, requests, re, json\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#scrape username instagram that we want to analyze\n",
    "for i in range(10): #bcs the number of webpage is until 10\n",
    "    a = i+1\n",
    "    #if response 200 is that webpage can be scraped\n",
    "    url = f'https://starngage.com/app/global/influencer/ranking/brazil'\n",
    "    \n",
    "    #call function\n",
    "    ranking, username, category = scrape_username(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://starngage.com/app/global/influencer/ranking/brazil')\n",
    "print(f'response {response}')\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "list_username = soup.find_all('tr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#@UsernameCountry/RegionTopicsFollowersEngagement Rate',\n",
       " '1Demi Lovato@ddlovatoBrazilSingerSongwritingMusicMusician145.2M0.35%',\n",
       " '2Vin Diesel@vindieselBrazilProducersDirectorActors85.1M0.95%',\n",
       " '3Shakira@shakiraBrazilMusicSingerMusician/Band77.8M1.07%',\n",
       " '4Shawn Mendes@shawnmendesBrazilMusicSingerSongwritingMusician70.8M2.20%',\n",
       " '5Anitta üé§@anittaBrazilArtMusicSinger63.5M0.86%',\n",
       " '6Millie Bobby Brown@milliebobbybrownBrazilCelebrityActors59.9M4.91%',\n",
       " '7Whindersson Nunes@whinderssonnunesBrazilCelebrityComedyComedian58.4M0.70%',\n",
       " 'Sign up to view the full list',\n",
       " '8Tata Werneck@tatawerneckBrazilArtActorsArtist54.4M0.16%',\n",
       " '9Lady Gaga@ladygagaBrazilShoppingMusicSingerSongwritingMusician53.4M0.78%',\n",
       " '10Robert Downey Jr. Official@robertdowneyjrBrazilActors53.4M1.59%',\n",
       " '11James RodriÃÅguez@jamesrodriguez10BrazilSportsSoccer49.7M0.90%',\n",
       " '12Larissa Manoela@larissamanoelaBrazilBusiness and FinanceArtCelebrityMusicActors47.8M0.67%',\n",
       " '13Zlatan Ibrahimoviƒá@iamzlatanibrahimovicBrazilSoccer47.4M1.60%',\n",
       " '14+A@maisaBrazilArtMusicSinger45.4M0.30%',\n",
       " '15Nike Football (Soccer)@nikefootballBrazilSoccerSportsFootwear43.6M0.30%',\n",
       " '16üèõ Gusttavo Lima üèõ@gusttavolimaBrazilArtSinger43.5M0.70%',\n",
       " '17Marilia MendoncÃßa@mariliamendoncacantoraBrazilSingerMusic41.8M1.82%',\n",
       " '18Virginia Fonseca Costa@virginiaBrazilArtModelingHumorCelebritiesFilm, Music & BooksAnimals & PetsArtist41.5M5.10%',\n",
       " '19Marina Ruy Barbosa@marinaruybarbosaBrazilArtCelebrityActorsCelebritiesHair & BeautyHealth & Fitness41.2M0.20%',\n",
       " '20Wesley SafadaÃÉo@wesleysafadaoBrazilMusicSinger37.4M0.22%',\n",
       " '21Cole Sprouse@colesprouseBrazilActorsDay Care35.9M3.80%',\n",
       " '22Veveta@ivetesangaloBrazilArtTV HostActorsMusic34.5M0.40%',\n",
       " '23Paolla Oliveira@paollaoliveirarealBrazilLifestyleActorsFashion34.3M0.20%',\n",
       " '24Luan Santana@luansantanaBrazilSingerMusic32.8M0.10%',\n",
       " '25Juliette@julietteBrazilArtArtist32.6M1.81%',\n",
       " '26DanialvesD2 My Twitter@danialvesBrazilSoccerSports32M0.50%',\n",
       " '27Sabrina Sato@sabrinasatoBrazilAutomotiveTV Host31.7M0.11%',\n",
       " 'Sign up to view the full list',\n",
       " '28Eliana Michaelichen@elianaBrazilArtTV ShowsMusicActors30.9M0.26%',\n",
       " '29Juliana Paes@julianapaesBrazilCelebrityArtVisualizations30.7M0.10%',\n",
       " '30LU√çSA SONZA@luisasonzaBrazilArtMusicLifestyleSingerDesignCelebrities30.5M1.10%',\n",
       " '31Lili Reinhart@lilireinhartBrazilCelebrityActorsActor28.7M3.11%',\n",
       " '32isis valverde@isisvalverdeBrazilArtCelebrityLifestyleActors28M0.13%',\n",
       " '33KEVINHO@kevinhoBrazilArtMusicSinger28M0.15%',\n",
       " '34Alok Petrillo@alokBrazilArtProducersMusic28M0.54%',\n",
       " '35Ludmilla@ludmillaBrazilMusicSingerSongwritingDanceCelebritiesFilm, Music & BooksAnimals & Pets27.2M0.50%',\n",
       " '36camila mendes@camimendesBrazilActorsActor27.2M3.00%',\n",
       " '37BAD MI ‚ö°Ô∏è MC MIRELLA@mirellaBrazilMarketing and Advertising26.6M2.30%',\n",
       " '38Simaria Mendes@simariaBrazilSingerMusicFashion26.2M0.60%',\n",
       " '39Carlinhos Maiaüåª@carlinhosmaiaofBrazilArtHumorLifestyle25.9M2.30%',\n",
       " '40Giovanna Ewbank@gioewbankBrazilCelebrityModelingActors25.7M4.00%',\n",
       " '41Viih Tube@viihtubeBrazilArtModelingLifestyleCelebritiesHumorGameCars & Motorcycles25.6M2.96%',\n",
       " '42Madelaine Petsch@madelameBrazilCelebrityActors25.4M7.60%',\n",
       " '43Deborah Secco@dedeseccoBrazilCelebrityActorsCelebritiesDesign25.1M0.14%',\n",
       " '44Liam Payne@liampayneBrazilShoppingSinger24.4M1.80%',\n",
       " '45Rodrigo Faro@rodrigofaroBrazilCelebrityArtSingerActorsMusic24.2M0.14%',\n",
       " '46Ashley Benson@ashleybensonBrazilActors23.4M0.41%',\n",
       " '47Philippe Coutinho@phil.coutinhoBrazilSoccer23.4M2.90%',\n",
       " 'Sign up to view the full list',\n",
       " '48Claudia Leitte@claudialeitteBrazilMusicSinger23M0.30%',\n",
       " '49Ronaldo@ronaldoBrazilSoccerSportsEntrepreneur23M0.76%',\n",
       " '50RAFA KALIMANN@rafakalimannBrazilModeling22.4M1.00%',\n",
       " '51pefabiodemelo@pefabiodemeloBrazilLifestyle22.1M1.00%',\n",
       " '52Sincero Oficial@sincerooficialBrazilHumorComedyPhotographyHair & Beauty21.8M0.75%',\n",
       " '53üá´\\u200aüá™\\u200aüá∑\\u200aüá≥\\u200aüá¶\\u200aüá≥\\u200a\\u200aüá©\\u200aüá¶\\u200a üá∏\\u200aüá¥\\u200aüá∫\\u200aüáø\\u200aüá¶@fernandasouzaoficialBrazilArtSingerActorsMusic21.7M0.40%',\n",
       " '54Bruno Gagliasso@brunogagliassoBrazilCelebrityActorsCelebritiesHumor21.6M0.33%',\n",
       " '55Netflix Brasil@netflixbrasilBrazilNews&PoliticsTV Shows21.5M0.80%',\n",
       " '56JADE üå™@jadepiconBrazilFashionModelingCelebritiesHumorCars & MotorcyclesTechnologyEducation21.5M2.51%',\n",
       " '57Everson Silva@tirullipaBrazilHumor21.4M0.50%',\n",
       " '58Simone e Simaria@simoneesimariaBrazilArtBandCelebritiesAnimals & PetsHumor21.2M0.50%',\n",
       " '59All and everything@cleoBrazilMarketing and AdvertisingCelebritiesFilm, Music & Books20.7M0.22%',\n",
       " '60LUCAS RANGEL@lucasranngelBrazilBeautyBusiness and FinanceMusicLifestyleCelebritiesFilm, Music & Books20.4M1.62%',\n",
       " '61Luciano Huck@lucianohuckBrazilEntertainmentTV HostTV Shows20.3M0.78%',\n",
       " '62Gisele BuÃàndchen@giseleBrazilFashionModeling20.2M1.87%',\n",
       " '63David Luiz@davidluiz23BrazilSoccerSports20.2M1.40%',\n",
       " '64Thalia@thaliaBrazilMusicSinger20.1M0.26%',\n",
       " '65Caio Castro@caiocastroBrazilArtSurfingActors20.1M0.20%',\n",
       " '66Coldplay@coldplayBrazilMusicSingerRock20.1M3.26%',\n",
       " '67JuÃÅlio Cocielo Estaniecki@cocieloBrazilCelebrityActorsComedyHumor19.9M3.17%',\n",
       " 'Sign up to view the full list',\n",
       " '68Jair M. Bolsonaro@jairmessiasbolsonaroBrazilPolitics19.7M1.30%',\n",
       " '69ZeÃÅ@zefelipecantorBrazilArtSongwriting19.6M3.30%',\n",
       " '70Rafael Vitti@rafaavittiBrazilActorsCelebritiesAnimals & PetsTechnology19.5M0.80%',\n",
       " '71David Michigan ‚ö°Ô∏è@davidmichiganBrazilCelebrityCelebritiesHealth & Fitness19.3M0.21%',\n",
       " '72Flavia Pavanelli@flaviapavanelliBrazilMarketing and AdvertisingLifestyleActorsCelebrities19.1M0.24%',\n",
       " '73Mari Maria@marimariaBrazilBeautyArtStylingArtist19M1.60%',\n",
       " '74KJ Apa@kjapaBrazilActors19M6.90%',\n",
       " '75Camila Queiroz@camilaqueirozBrazilArtActors18.8M0.30%',\n",
       " '76Iran Ferreira@luvadepedreiroBrazil18.6M9.13%',\n",
       " '77Noah@ncentineoBrazilActors18.6M4.70%',\n",
       " '78Lexa@lexaBrazilMusicSingerCelebritiesFilm, Music & Books18.2M0.44%',\n",
       " '79Sou Eu Na Vida@soueunavidaBrazilEntertainmentMemesCelebritiesHumorTechnologyPhotographyEntertainment Website18.1M1.85%',\n",
       " '80Lucas Lucco@lucasluccoBrazilArtSingerLifestyle17.9M0.10%',\n",
       " '81Jorge e Mateus@jorgeemateusBrazilMusic17.4M0.50%',\n",
       " '82CHOQUEI@choqueiBrazilNewsEvents17.4M0.80%',\n",
       " '83Ricky Martin@ricky_martinBrazilActorsMusicWriters17.3M1.10%',\n",
       " '84Juliana Salimeni üíñ@jujusalimeniBrazilArtModeling17.2M0.20%',\n",
       " '85Kak√°@kakaBrazilSoccerSports17.1M0.60%',\n",
       " '86IZA@izaBrazilMusicSinger16.5M0.66%',\n",
       " '87TainaÃÅ Costa üèçÔ∏è@tainaBrazilMarketing and AdvertisingModeling16.3M3.68%',\n",
       " 'Sign up to view the full list',\n",
       " '88Felipe Neto ü¶â@felipenetoBrazilCelebritiesFilm, Music & BooksAnimals & PetsTechnology16.3M1.50%',\n",
       " '89Perrie Edwards üñ§@perrieedwardsBrazilSingerMusicArtArtist16M4.44%',\n",
       " '90Leonardo@leonardoBrazilMusic15.9M1.00%',\n",
       " '91paulogustavo31@paulogustavo31BrazilArtActors15.8M4.80%',\n",
       " '92Gabriel Jesus@dejesusoficialBrazilSoccerSports15.8M1.20%',\n",
       " '93Andressa Suita@andressasuitaBrazilModelingCelebritiesAnimals & PetsFashion15.7M2.19%',\n",
       " '94Martin Garrix@martingarrixBrazilDJMusicProducers15.7M0.65%',\n",
       " '95POCAH@pocahBrazilArtSingerCelebritiesHealth & FitnessFilm, Music & Books15.4M0.49%',\n",
       " '96Manu Gavassi@manugavassiBrazilArtActorsCelebritiesFilm, Music & Books15.4M0.19%',\n",
       " '97GKAY@gessicakayaneBrazilHumorCelebritiesAnimals & Pets15.2M2.00%',\n",
       " '98Thais Fersoza@tatafersozaBrazilArtLifestyleActorsCelebrities15.1M0.20%',\n",
       " '99L√©o Santana@leosantanaBrazilSinger15.1M0.90%',\n",
       " '100Sophia Valverde¬Æ@sophiavalverdeBrazilActorsCelebritiesFashionHair & BeautyDesign15M0.38%']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "newlist_usernames = [a.get_text(strip=True) for a in list_username]\n",
    "newlist_usernames\n",
    "#print(re.findall(['['@']([a-z0-9])+'], newlist_usernames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_dict = {\n",
    "    'username':username,\n",
    "    'ranking':ranking,\n",
    "    'category':category\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign to dataframe\n",
    "df = pd.DataFrame(inf_dict)\n",
    "\n",
    "#do some preprocessing\n",
    "df['username_2'] = df['username'].apply(lambda x: x[1:])\n",
    "df['category'] = df['category'].astype('str')\n",
    "df_2 = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['Singer', 'Songwriting', 'Music', 'Musician']\",\n",
       " \"['Producers', 'Director', 'Actors']\",\n",
       " \"['Music', 'Singer', 'Musician/Band']\",\n",
       " \"['Music', 'Singer', 'Songwriting', 'Musician']\",\n",
       " \"['Art', 'Music', 'Singer']\",\n",
       " \"['Celebrity', 'Actors']\",\n",
       " \"['Celebrity', 'Comedy', 'Comedian']\",\n",
       " \"['Art', 'Actors', 'Artist']\",\n",
       " \"['Shopping', 'Music', 'Singer', 'Songwriting', 'Musician']\",\n",
       " \"['Actors']\",\n",
       " \"['Sports', 'Soccer']\",\n",
       " \"['Business and Finance', 'Art', 'Celebrity', 'Music', 'Actors']\",\n",
       " \"['Soccer']\",\n",
       " \"['Art', 'Music', 'Singer']\",\n",
       " \"['Soccer', 'Sports', 'Footwear']\",\n",
       " \"['Art', 'Singer']\",\n",
       " \"['Singer', 'Music']\",\n",
       " \"['Art', 'Modeling', 'Humor', 'Celebrities', 'Film, Music & Books', 'Animals & Pets', 'Artist']\",\n",
       " \"['Art', 'Celebrity', 'Actors', 'Celebrities', 'Hair & Beauty', 'Health & Fitness']\",\n",
       " \"['Music', 'Singer']\",\n",
       " \"['Actors', 'Day Care']\",\n",
       " \"['Art', 'TV Host', 'Actors', 'Music']\",\n",
       " \"['Lifestyle', 'Actors', 'Fashion']\",\n",
       " \"['Singer', 'Music']\",\n",
       " \"['Art', 'Artist']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Automotive', 'TV Host']\",\n",
       " \"['Art', 'TV Shows', 'Music', 'Actors']\",\n",
       " \"['Celebrity', 'Art', 'Visualizations']\",\n",
       " \"['Art', 'Music', 'Lifestyle', 'Singer', 'Design', 'Celebrities']\",\n",
       " \"['Celebrity', 'Actors', 'Actor']\",\n",
       " \"['Art', 'Celebrity', 'Lifestyle', 'Actors']\",\n",
       " \"['Art', 'Music', 'Singer']\",\n",
       " \"['Art', 'Producers', 'Music']\",\n",
       " \"['Music', 'Singer', 'Songwriting', 'Dance', 'Celebrities', 'Film, Music & Books', 'Animals & Pets']\",\n",
       " \"['Actors', 'Actor']\",\n",
       " \"['Marketing and Advertising']\",\n",
       " \"['Singer', 'Music', 'Fashion']\",\n",
       " \"['Art', 'Humor', 'Lifestyle']\",\n",
       " \"['Celebrity', 'Modeling', 'Actors']\",\n",
       " \"['Art', 'Modeling', 'Lifestyle', 'Celebrities', 'Humor', 'Game', 'Cars & Motorcycles']\",\n",
       " \"['Celebrity', 'Actors']\",\n",
       " \"['Celebrity', 'Actors', 'Celebrities', 'Design']\",\n",
       " \"['Shopping', 'Singer']\",\n",
       " \"['Celebrity', 'Art', 'Singer', 'Actors', 'Music']\",\n",
       " \"['Actors']\",\n",
       " \"['Soccer']\",\n",
       " \"['Music', 'Singer']\",\n",
       " \"['Soccer', 'Sports', 'Entrepreneur']\",\n",
       " \"['Modeling']\",\n",
       " \"['Lifestyle']\",\n",
       " \"['Humor', 'Comedy', 'Photography', 'Hair & Beauty']\",\n",
       " \"['Art', 'Singer', 'Actors', 'Music']\",\n",
       " \"['Celebrity', 'Actors', 'Celebrities', 'Humor']\",\n",
       " \"['News&Politics', 'TV Shows']\",\n",
       " \"['Fashion', 'Modeling', 'Celebrities', 'Humor', 'Cars & Motorcycles', 'Technology', 'Education']\",\n",
       " \"['Humor']\",\n",
       " \"['Art', 'Band', 'Celebrities', 'Animals & Pets', 'Humor']\",\n",
       " \"['Marketing and Advertising', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Beauty', 'Business and Finance', 'Music', 'Lifestyle', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Entertainment', 'TV Host', 'TV Shows']\",\n",
       " \"['Fashion', 'Modeling']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Music', 'Singer']\",\n",
       " \"['Art', 'Surfing', 'Actors']\",\n",
       " \"['Music', 'Singer', 'Rock']\",\n",
       " \"['Celebrity', 'Actors', 'Comedy', 'Humor']\",\n",
       " \"['Politics']\",\n",
       " \"['Art', 'Songwriting']\",\n",
       " \"['Actors', 'Celebrities', 'Animals & Pets', 'Technology']\",\n",
       " \"['Celebrity', 'Celebrities', 'Health & Fitness']\",\n",
       " \"['Marketing and Advertising', 'Lifestyle', 'Actors', 'Celebrities']\",\n",
       " \"['Beauty', 'Art', 'Styling', 'Artist']\",\n",
       " \"['Actors']\",\n",
       " \"['Art', 'Actors']\",\n",
       " '[]',\n",
       " \"['Actors']\",\n",
       " \"['Music', 'Singer', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Entertainment', 'Memes', 'Celebrities', 'Humor', 'Technology', 'Photography', 'Entertainment Website']\",\n",
       " \"['Art', 'Singer', 'Lifestyle']\",\n",
       " \"['Music']\",\n",
       " \"['News', 'Events']\",\n",
       " \"['Actors', 'Music', 'Writers']\",\n",
       " \"['Art', 'Modeling']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Music', 'Singer']\",\n",
       " \"['Marketing and Advertising', 'Modeling']\",\n",
       " \"['Celebrities', 'Film, Music & Books', 'Animals & Pets', 'Technology']\",\n",
       " \"['Singer', 'Music', 'Art', 'Artist']\",\n",
       " \"['Music']\",\n",
       " \"['Art', 'Actors']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Modeling', 'Celebrities', 'Animals & Pets', 'Fashion']\",\n",
       " \"['DJ', 'Music', 'Producers']\",\n",
       " \"['Art', 'Singer', 'Celebrities', 'Health & Fitness', 'Film, Music & Books']\",\n",
       " \"['Art', 'Actors', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Humor', 'Celebrities', 'Animals & Pets']\",\n",
       " \"['Art', 'Lifestyle', 'Actors', 'Celebrities']\",\n",
       " \"['Singer']\",\n",
       " \"['Actors', 'Celebrities', 'Fashion', 'Hair & Beauty', 'Design']\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_2[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c98bfc02f18715a8bb7823da55659e8e7ec96d04f977302cc17c329cb407a447"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
