{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, time, urllib.request, openpyxl, operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from openpyxl import Workbook\n",
    "import sys, requests, re, json\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Create Empty List\n",
    "ranking = []\n",
    "username = []\n",
    "category = []\n",
    "category_2 = []\n",
    "\n",
    "def scrape_username(url):\n",
    "    \n",
    "    #accesing and parsing the input url\n",
    "    response = requests.get(url)\n",
    "    print(f'response {response}')\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    list_username = soup.find_all('tr')\n",
    "    \n",
    "    #looping to the element that we want to scrape\n",
    "    for p in list(list_username):\n",
    "        try:\n",
    "            #getting the information (rank, names, and category)\n",
    "            rank = p.find('td', 'align-middle').get_text().strip()\n",
    "            ranking.append(rank)\n",
    "\n",
    "            # i am having trouble with this part, because i could get the categories, but not the @s from the page  ):\n",
    "            # tried to do the \"same logic\" as the code does for category, but at the end it says I have a ValueError: All arrays must be of the same length\n",
    "\n",
    "            # name = p.find_all('a', \"_blank\").get_text().strip()\n",
    "            # name_2 = []\n",
    "            # for item in name:\n",
    "            #     new_var = item.find('a', 'link').get_text()\n",
    "            #     name_2.append(new_var)\n",
    "            # username.append(name_2)\n",
    "\n",
    "            name = p.find('a').get_text().strip()\n",
    "            username.append(name)\n",
    "\n",
    "\n",
    "            cat = p.find_all('span', 'badge badge-pill badge-light samll font-weight-normal text-muted') #i had to change this part here to get categories\n",
    "            category_2 = []\n",
    "            for c in cat:\n",
    "                d = c.find('a', 'link').get_text()\n",
    "                category_2.append(d)\n",
    "            category.append(category_2)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return ranking, username, category\n",
    "\n",
    "#function to scrape general information\n",
    "def scrape_general_info(url):\n",
    "    # instagram URL \n",
    "    URL = url\n",
    "\n",
    "    # creating a dictionary \n",
    "    data = {} \n",
    "\n",
    "    # getting the request from url \n",
    "    r = requests.get(URL)\n",
    "\n",
    "    # converting the text \n",
    "    s = BeautifulSoup(r.text, \"html.parser\") \n",
    "\n",
    "    # finding meta info \n",
    "    meta = s.find(\"meta\", property =\"og:description\")\n",
    "\n",
    "    #searching followers, followeing and number of posts info\n",
    "    meta_2 = meta.attrs['content']\n",
    "    meta_3 = meta_2.split(\"-\")[0].split(\" \")\n",
    "\n",
    "    # assigning the values \n",
    "    data['Followers'] = meta_3[0] \n",
    "    data['Following'] = meta_3[2] \n",
    "    data['Posts'] = meta_3[4]\n",
    "    \n",
    "    return data\n",
    "\n",
    "#Create Empty List\n",
    "link = []\n",
    "names = []\n",
    "\n",
    "def get_influencer_link(username):\n",
    "    #to influencer url\n",
    "    url = f'https://www.instagram.com/{username}/'\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "\n",
    "    time.sleep(5)\n",
    "\n",
    "    i = 0\n",
    "    while i < 8:   \n",
    "        try:\n",
    "            #get the links\n",
    "            pages = driver.find_elements_by_tag_name('a')\n",
    "            for data in pages:\n",
    "                data_2 = data.get_attribute(\"href\")\n",
    "                if '/p/' in data_2:\n",
    "                    link.append(data.get_attribute(\"href\"))\n",
    "                    names.append(username)\n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            # Wait to load page\n",
    "            time.sleep(1)\n",
    "            i += 1\n",
    "        except:\n",
    "            i += 1\n",
    "            continue\n",
    "    driver.quit()\n",
    "\n",
    "    return link, names\n",
    "\n",
    "\n",
    "likes = []\n",
    "comment_counts = []\n",
    "dates = []\n",
    "captions = []\n",
    "type_posts = []\n",
    "links = []\n",
    "i = 0\n",
    "n = 0\n",
    "\n",
    "def get_information(link):    \n",
    "    try:\n",
    "        global i, n\n",
    "        \n",
    "        #accessing and parsing the website url\n",
    "        url = link\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content)\n",
    "        \n",
    "        #find element that contain information\n",
    "        body = soup.find('body')\n",
    "        script = body.find('script')\n",
    "        raw = script.text.strip().replace('window._sharedData =', '').replace(';', '')\n",
    "        json_data=json.loads(raw)\n",
    "        posts =json_data['entry_data']['PostPage'][0]['graphql']\n",
    "        posts= json.dumps(posts)\n",
    "        posts = json.loads(posts)\n",
    "        \n",
    "        #acquiring information\n",
    "        like = posts['shortcode_media']['edge_media_preview_like']['count']\n",
    "        comment_count = posts['shortcode_media']['edge_media_to_parent_comment']['count']\n",
    "        date = posts['shortcode_media']['taken_at_timestamp']\n",
    "        caption = posts['shortcode_media']['edge_media_to_caption']['edges'][0]['node']['text']\n",
    "        type_post = posts['shortcode_media']['__typename']\n",
    "        likes.append(like)\n",
    "        comment_counts.append(comment_count)\n",
    "        dates.append(date)\n",
    "        captions.append(caption)\n",
    "        type_posts.append(type_post)\n",
    "        links.append(link)\n",
    "        i += 1\n",
    "    except:\n",
    "        i += 1\n",
    "        n += 1\n",
    "        print(f'number of link error {n} at iteration {i}')\n",
    "        pass\n",
    "    return likes, comment_counts, dates, captions, type_posts, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, platform, time, urllib.request, openpyxl, operator\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from openpyxl import Workbook\n",
    "import sys, requests, re, json\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n",
      "response <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "#scrape username instagram that we want to analyze\n",
    "for i in range(10): #bcs the number of webpage is until 10\n",
    "    a = i+1\n",
    "    #if response 200 is that webpage can be scraped\n",
    "    url = f'https://starngage.com/app/global/influencer/ranking/brazil'\n",
    "    \n",
    "    #call function\n",
    "    ranking, username, category = scrape_username(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response <Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://starngage.com/app/global/influencer/ranking/brazil')\n",
    "print(f'response {response}')\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "list_username = soup.find_all('tr')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#@UsernameCountry/RegionTopicsFollowersEngagement Rate',\n",
       " '1Demi Lovato@ddlovatoBrazilSingerSongwritingMusicMusician141.6M0.24%',\n",
       " '2Vin Diesel@vindieselBrazilProducersDirectorActors83M0.56%',\n",
       " '3Shakira@shakiraBrazilMusicSingerMusician/Band76.2M0.81%',\n",
       " '4Shawn Mendes@shawnmendesBrazilMusicSingerSongwritingMusician70.4M2.61%',\n",
       " '5camila@camila_cabelloBrazilFashionSingerMusicModeling65.4M1.07%',\n",
       " '6Anitta 游꿗@anittaBrazilArtMusicSinger63.3M0.70%',\n",
       " '7MALUMA@malumaBrazilArtMusicSinger62.8M1.10%',\n",
       " 'Sign up to view the full list',\n",
       " '8Millie Bobby Brown@milliebobbybrownBrazilCelebrityActors58.7M7.18%',\n",
       " '9Whindersson Nunes@whinderssonnunesBrazilCelebrityComedyComedian58.4M0.70%',\n",
       " '10Lady Gaga@ladygagaBrazilShoppingMusicSingerSongwritingMusician53.4M0.78%',\n",
       " '11Robert Downey Jr. Official@robertdowneyjrBrazilActors53.4M1.59%',\n",
       " '12Tata Werneck@tatawerneckBrazilActorsArtist53M0.40%',\n",
       " '13James Rodri패guez@jamesrodriguez10BrazilSportsSoccer49.7M0.90%',\n",
       " '14Zlatan Ibrahimovi캖@iamzlatanibrahimovicBrazilSoccer47.4M1.60%',\n",
       " '15Larissa Manoela@larissamanoelaBrazilCelebrityArtMusicActors45.7M0.20%',\n",
       " '16Nike Football (Soccer)@nikefootballBrazilSoccerSportsFootwear43.6M0.30%',\n",
       " '17游끹 Gusttavo Lima 游끹@gusttavolimaBrazilArtSinger43.5M0.70%',\n",
       " '18+A@maisaBrazilArtMusicSinger43.3M0.50%',\n",
       " '19Marilia Mendonc퍊a@mariliamendoncacantoraBrazilSingerMusic41.8M1.82%',\n",
       " '20Marina Ruy Barbosa@marinaruybarbosaBrazilArtCelebrityActorsCelebritiesHair & BeautyHealth & Fitness41.1M0.21%',\n",
       " '21Virginia Fonseca Costa@virginiaBrazilArtModelingHumorCelebritiesFilm, Music & BooksAnimals & PetsArtist38.6M2.50%',\n",
       " '22Wesley Safada팪o@wesleysafadaoBrazilMusicSinger37.4M0.22%',\n",
       " '23Cole Sprouse@colesprouseBrazilActorsDay Care35.9M3.80%',\n",
       " '24Veveta@ivetesangaloBrazilArtTV HostActorsMusic34.5M0.40%',\n",
       " '25Paolla Oliveira@paollaoliveirarealBrazilLifestyleActorsFashion34.3M0.20%',\n",
       " '26Juliette@julietteBrazilArtist33.8M0.80%',\n",
       " '27Luan Santana@luansantanaBrazilSingerMusic32.8M0.10%',\n",
       " 'Sign up to view the full list',\n",
       " '28DanialvesD2 My Twitter@danialvesBrazilSoccerSports32M0.50%',\n",
       " '29Sabrina Sato@sabrinasatoBrazilAutomotiveTV Host31.7M0.11%',\n",
       " '30Eliana Michaelichen@elianaBrazilArtTV ShowsMusicActors30.9M0.26%',\n",
       " '31Juliana Paes@julianapaesBrazilCelebrityArtVisualizations30.7M0.10%',\n",
       " '32LU칈SA SONZA@luisasonzaBrazilArtMusicLifestyleSingerDesignCelebrities29.2M1.10%',\n",
       " '33Lili Reinhart@lilireinhartBrazilCelebrityActorsActor28.7M3.11%',\n",
       " '34KEVINHO@kevinhoBrazilArtMusicSinger28M0.15%',\n",
       " '35Alok Petrillo@alokBrazilArtProducersMusic28M0.54%',\n",
       " '36Ludmilla@ludmillaBrazilMusicSingerSongwritingDanceCelebritiesFilm, Music & BooksAnimals & Pets27.2M0.50%',\n",
       " '37camila mendes@camimendesBrazilActorsActor26.9M6.20%',\n",
       " '38isis valverde@isisvalverdeBrazilCelebrityArtLifestyleActors26.7M0.50%',\n",
       " '39Simaria Mendes@simariaBrazilSingerMusicFashion26.2M0.60%',\n",
       " '40Carlinhos Maia游꺝@carlinhosmaiaofBrazilArtHumorLifestyle25.9M2.30%',\n",
       " '41Giovanna Ewbank@gioewbankBrazilCelebrityModelingActors25.7M4.00%',\n",
       " '42Madelaine Petsch@madelameBrazilCelebrityActors25.4M7.60%',\n",
       " '43Viih Tube@viihtubeBrazilArtModelingLifestyleCelebritiesHumorGameCars & Motorcycles24.6M2.39%',\n",
       " '44Liam Payne@liampayneBrazilShoppingSinger24.4M1.80%',\n",
       " '45Rodrigo Faro@rodrigofaroBrazilCelebrityArtSingerActorsMusic24.2M0.14%',\n",
       " '46Ashley Benson@ashleybensonBrazilActors23.4M0.41%',\n",
       " '47Philippe Coutinho@phil.coutinhoBrazilSoccer23.4M2.90%',\n",
       " 'Sign up to view the full list',\n",
       " '48Claudia Leitte@claudialeitteBrazilMusicSinger23M0.30%',\n",
       " '49Ronaldo@ronaldoBrazilSoccerSportsEntrepreneur23M0.76%',\n",
       " '50RAFA KALIMANN@rafakalimannBrazilModeling22.4M1.00%',\n",
       " '51Deborah Secco@dedeseccoBrazilCelebrityActorsCelebritiesDesign22.2M0.30%',\n",
       " '52pefabiodemelo@pefabiodemeloBrazilLifestyle22.1M1.00%',\n",
       " '53Bruno Gagliasso@brunogagliassoBrazilCelebrityActorsCelebritiesHumor21.7M0.18%',\n",
       " '54游쁖\u200a游뾮\u200a游윺\u200a游쓮\u200a游뵢\u200a游쓮\u200a\\u200a游뼆\u200a游뵢\u200a 游\\u200a游\\u200a游죞\u200a游쯒\u200a游@fernandasouzaoficialBrazilArtSingerActorsMusic21.7M0.40%',\n",
       " '55Netflix Brasil@netflixbrasilBrazilNews&PoliticsTV Shows21.5M0.80%',\n",
       " '56Everson Silva@tirullipaBrazilHumor21.4M0.50%',\n",
       " '57Sincero Oficial@sincerooficialBrazilHumorComedyPhotographyHair & Beauty21.3M0.40%',\n",
       " '58Simone e Simaria@simoneesimariaBrazilArtBandCelebritiesAnimals & PetsHumor21.2M0.50%',\n",
       " '59All and everything@cleoBrazilMarketing and AdvertisingCelebritiesFilm, Music & Books20.7M0.22%',\n",
       " '60@mirellaBrazilMarketing and Advertising20.3M4.30%',\n",
       " '61Luciano Huck@lucianohuckBrazilEntertainmentTV HostTV Shows20.3M0.50%',\n",
       " '62LUCAS RANGEL@lucasranngelBrazilBusiness and FinanceMusicLifestyleCelebritiesFilm, Music & Books20.2M1.36%',\n",
       " '63David Luiz@davidluiz23BrazilSoccerSports20.2M1.40%',\n",
       " '64Caio Castro@caiocastroBrazilArtSurfingActors20.1M0.20%',\n",
       " '65Jair M. Bolsonaro@jairmessiasbolsonaroBrazilPolitics19.7M1.30%',\n",
       " '66Ze패@zefelipecantorBrazilArtSongwriting19.6M3.30%',\n",
       " '67Rafael Vitti@rafaavittiBrazilActorsCelebritiesAnimals & PetsTechnology19.3M0.63%',\n",
       " 'Sign up to view the full list',\n",
       " '68Mari Maria@marimariaBrazilBeautyArtStylingArtist19M1.60%',\n",
       " '69KJ Apa@kjapaBrazilActors19M6.90%',\n",
       " '70Camila Queiroz@camilaqueirozBrazilArtActors18.8M0.30%',\n",
       " '71Thalia@thaliaBrazilMusicSinger18.6M0.60%',\n",
       " '72Iran Ferreira@luvadepedreiroBrazil18.6M9.13%',\n",
       " '73Noah@ncentineoBrazilActors18.6M4.70%',\n",
       " '74Flavia Pavanelli@flaviapavanelliBrazilMarketing and AdvertisingLifestyleActorsCelebrities18.4M0.80%',\n",
       " '75Gisele Bu팯ndchen@giseleBrazilFashionModeling18.1M2.40%',\n",
       " '76Lexa@lexaBrazilMusicSingerCelebritiesFilm, Music & Books18.1M0.23%',\n",
       " '77Lucas Lucco@lucasluccoBrazilArtSingerLifestyle17.9M0.10%',\n",
       " '78Sou Eu Na Vida@soueunavidaBrazilEntertainmentMemesCelebritiesHumorTechnologyPhotographyEntertainment Website17.6M1.50%',\n",
       " '79Jorge e Mateus@jorgeemateusBrazilMusic17.4M0.50%',\n",
       " '80CHOQUEI@choqueiBrazilNewsEvents17.4M0.80%',\n",
       " '81Ricky Martin@ricky_martinBrazilActorsMusicWriters17.3M1.10%',\n",
       " '82Juliana Salimeni 游눘@jujusalimeniBrazilArtModeling17.2M0.20%',\n",
       " '83Kak치@kakaBrazilSoccerSports17.1M0.60%',\n",
       " '84Ju패lio Cocielo Estaniecki@cocieloBrazilCelebrityActorsComedyHumor16.8M2.40%',\n",
       " '85Coldplay@coldplayBrazilMusicSingerRock16.7M0.76%',\n",
       " '86Felipe Neto 游불@felipenetoBrazilCelebritiesFilm, Music & BooksAnimals & PetsTechnology16.3M1.50%',\n",
       " '87Taina패 Costa@tainaBrazilMarketing and AdvertisingModeling16.1M3.07%',\n",
       " 'Sign up to view the full list',\n",
       " '88Perrie Edwards 游둯@perrieedwardsBrazilSingerMusicArtArtist16M4.44%',\n",
       " '89Leonardo@leonardoBrazilMusic15.9M1.00%',\n",
       " '90paulogustavo31@paulogustavo31BrazilArtActors15.8M4.80%',\n",
       " '91Gabriel Jesus@dejesusoficialBrazilSoccerSports15.8M1.20%',\n",
       " '92Andressa Suita@andressasuitaBrazilModelingCelebritiesAnimals & PetsFashion15.7M2.19%',\n",
       " '93Martin Garrix@martingarrixBrazilDJMusicProducers15.7M0.65%',\n",
       " '94POCAH@pocahBrazilArtSingerCelebritiesHealth & FitnessFilm, Music & Books15.6M0.54%',\n",
       " '95Manu Gavassi@manugavassiBrazilArtActorsCelebritiesFilm, Music & Books15.3M0.30%',\n",
       " '96GKAY@gessicakayaneBrazilHumorCelebritiesAnimals & Pets15.2M2.00%',\n",
       " '97Thais Fersoza@tatafersozaBrazilArtLifestyleActorsCelebrities15.1M0.20%',\n",
       " '98L칠o Santana@leosantanaBrazilSinger15.1M0.90%',\n",
       " '99IZA@izaBrazilMusicSinger14.9M1.40%',\n",
       " '100KAROL SEVILLA@karolsevillaofcBrazilActorsModelingFashion14.8M0.90%']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "newlist_usernames = [a.get_text(strip=True) for a in list_username]\n",
    "newlist_usernames\n",
    "#print(re.findall(['['@']([a-z0-9])+'], newlist_usernames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_dict = {\n",
    "    'username':username,\n",
    "    'ranking':ranking,\n",
    "    'category':category\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign to dataframe\n",
    "df = pd.DataFrame(inf_dict)\n",
    "\n",
    "#do some preprocessing\n",
    "df['username_2'] = df['username'].apply(lambda x: x[1:])\n",
    "df['category'] = df['category'].astype('str')\n",
    "df_2 = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"['Singer', 'Songwriting', 'Music', 'Musician']\",\n",
       " \"['Producers', 'Director', 'Actors']\",\n",
       " \"['Music', 'Singer', 'Musician/Band']\",\n",
       " \"['Music', 'Singer', 'Songwriting', 'Musician']\",\n",
       " \"['Fashion', 'Singer', 'Music', 'Modeling', '']\",\n",
       " \"['Art', 'Music', 'Singer']\",\n",
       " \"['Art', 'Music', 'Singer']\",\n",
       " \"['Celebrity', 'Actors']\",\n",
       " \"['Celebrity', 'Comedy', 'Comedian']\",\n",
       " \"['Shopping', 'Music', 'Singer', 'Songwriting', 'Musician']\",\n",
       " \"['Actors']\",\n",
       " \"['Actors', 'Artist']\",\n",
       " \"['Sports', 'Soccer']\",\n",
       " \"['Soccer']\",\n",
       " \"['Celebrity', 'Art', 'Music', 'Actors']\",\n",
       " \"['Soccer', 'Sports', 'Footwear']\",\n",
       " \"['Art', 'Singer']\",\n",
       " \"['Art', 'Music', 'Singer']\",\n",
       " \"['Singer', 'Music']\",\n",
       " \"['Art', 'Celebrity', 'Actors', 'Celebrities', 'Hair & Beauty', 'Health & Fitness']\",\n",
       " \"['Art', 'Modeling', 'Humor', 'Celebrities', 'Film, Music & Books', 'Animals & Pets', 'Artist']\",\n",
       " \"['Music', 'Singer']\",\n",
       " \"['Actors', 'Day Care']\",\n",
       " \"['Art', 'TV Host', 'Actors', 'Music']\",\n",
       " \"['Lifestyle', 'Actors', 'Fashion']\",\n",
       " \"['Artist']\",\n",
       " \"['Singer', 'Music']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Automotive', 'TV Host']\",\n",
       " \"['Art', 'TV Shows', 'Music', 'Actors']\",\n",
       " \"['Celebrity', 'Art', 'Visualizations']\",\n",
       " \"['Art', 'Music', 'Lifestyle', 'Singer', 'Design', 'Celebrities']\",\n",
       " \"['Celebrity', 'Actors', 'Actor']\",\n",
       " \"['Art', 'Music', 'Singer']\",\n",
       " \"['Art', 'Producers', 'Music']\",\n",
       " \"['Music', 'Singer', 'Songwriting', 'Dance', 'Celebrities', 'Film, Music & Books', 'Animals & Pets']\",\n",
       " \"['Actors', 'Actor']\",\n",
       " \"['Celebrity', 'Art', 'Lifestyle', 'Actors']\",\n",
       " \"['Singer', 'Music', 'Fashion']\",\n",
       " \"['Art', 'Humor', 'Lifestyle']\",\n",
       " \"['Celebrity', 'Modeling', 'Actors']\",\n",
       " \"['Celebrity', 'Actors']\",\n",
       " \"['Art', 'Modeling', 'Lifestyle', 'Celebrities', 'Humor', 'Game', 'Cars & Motorcycles']\",\n",
       " \"['Shopping', 'Singer']\",\n",
       " \"['Celebrity', 'Art', 'Singer', 'Actors', 'Music']\",\n",
       " \"['Actors']\",\n",
       " \"['Soccer']\",\n",
       " \"['Music', 'Singer']\",\n",
       " \"['Soccer', 'Sports', 'Entrepreneur']\",\n",
       " \"['Modeling']\",\n",
       " \"['Celebrity', 'Actors', 'Celebrities', 'Design']\",\n",
       " \"['Lifestyle']\",\n",
       " \"['Celebrity', 'Actors', 'Celebrities', 'Humor']\",\n",
       " \"['Art', 'Singer', 'Actors', 'Music']\",\n",
       " \"['News&Politics', 'TV Shows']\",\n",
       " \"['Humor']\",\n",
       " \"['Humor', 'Comedy', 'Photography', 'Hair & Beauty']\",\n",
       " \"['Art', 'Band', 'Celebrities', 'Animals & Pets', 'Humor']\",\n",
       " \"['Marketing and Advertising', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Marketing and Advertising']\",\n",
       " \"['Entertainment', 'TV Host', 'TV Shows']\",\n",
       " \"['Business and Finance', 'Music', 'Lifestyle', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Art', 'Surfing', 'Actors']\",\n",
       " \"['Politics']\",\n",
       " \"['Art', 'Songwriting']\",\n",
       " \"['Actors', 'Celebrities', 'Animals & Pets', 'Technology']\",\n",
       " \"['Beauty', 'Art', 'Styling', 'Artist']\",\n",
       " \"['Actors']\",\n",
       " \"['Art', 'Actors']\",\n",
       " \"['Music', 'Singer']\",\n",
       " '[]',\n",
       " \"['Actors']\",\n",
       " \"['Marketing and Advertising', 'Lifestyle', 'Actors', 'Celebrities']\",\n",
       " \"['Fashion', 'Modeling']\",\n",
       " \"['Music', 'Singer', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Art', 'Singer', 'Lifestyle']\",\n",
       " \"['Entertainment', 'Memes', 'Celebrities', 'Humor', 'Technology', 'Photography', 'Entertainment Website']\",\n",
       " \"['Music']\",\n",
       " \"['News', 'Events']\",\n",
       " \"['Actors', 'Music', 'Writers']\",\n",
       " \"['Art', 'Modeling']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Celebrity', 'Actors', 'Comedy', 'Humor']\",\n",
       " \"['Music', 'Singer', 'Rock']\",\n",
       " \"['Celebrities', 'Film, Music & Books', 'Animals & Pets', 'Technology']\",\n",
       " \"['Marketing and Advertising', 'Modeling']\",\n",
       " \"['Singer', 'Music', 'Art', 'Artist']\",\n",
       " \"['Music']\",\n",
       " \"['Art', 'Actors']\",\n",
       " \"['Soccer', 'Sports']\",\n",
       " \"['Modeling', 'Celebrities', 'Animals & Pets', 'Fashion']\",\n",
       " \"['DJ', 'Music', 'Producers']\",\n",
       " \"['Art', 'Singer', 'Celebrities', 'Health & Fitness', 'Film, Music & Books']\",\n",
       " \"['Art', 'Actors', 'Celebrities', 'Film, Music & Books']\",\n",
       " \"['Humor', 'Celebrities', 'Animals & Pets']\",\n",
       " \"['Art', 'Lifestyle', 'Actors', 'Celebrities']\",\n",
       " \"['Singer']\",\n",
       " \"['Music', 'Singer']\",\n",
       " \"['Actors', 'Modeling', 'Fashion']\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_2[\"category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could just get information about the category using the code, and changing some details\n",
    "# if you want to compare to the original one, it's on the file \"test_indonesia\"\n",
    "# on the first cell i left some comments and also a part of code that i tried but it didn't worked. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ironhack')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f61e768a7a786be35d65123db8f98311986f4db302470b02f0c043ce57ff1dee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
